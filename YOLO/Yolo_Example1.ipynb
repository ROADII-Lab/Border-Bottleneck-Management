{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5309605b-cc01-4fa5-9c12-1d1d9b949b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ultralytics if necessary\n",
    "#%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f750cd-ff59-49c9-b04a-024ae3549114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.122  Python-3.10.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i7-1265U)\n",
      "Setup complete  (12 CPUs, 31.4 GB RAM, 452.5/916.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "df4d58b2-a072-4269-94e6-9f209941bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython import display\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "884d426c-5c63-4017-ba10-ddc8490ba3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"..\\img\\PDN_12_02_2025.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store sample images\n",
    "img1 = \"..\\img\\PDN_12_02_2025.png\"\n",
    "img2 = \"..\\img\\PDN_near_border.png\"\n",
    "\n",
    "# display image\n",
    "#display.Image(url=img1, width=500, height=300) # keep the image display small\n",
    "display.Image(url=img1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fae288a7-97e0-46ad-bba6-a21461956560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLO models\n",
    "model_n = YOLO(\"yolo11n.pt\")   # nano model\n",
    "model_s = YOLO(\"yolo11s.pt\")   # small model\n",
    "model_m = YOLO(\"yolo11m.pt\")   # medium model\n",
    "model_l = YOLO(\"yolo11l.pt\")   # large model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3c667fc-86c4-4384-a9b4-dd9a56637f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Joseph.Lynch.CTR\\Documents\\GitHub\\Border-Bottleneck-Management\\YOLO\\..\\img\\PDN_12_02_2025.png: 384x640 15 cars, 231.0ms\n",
      "Speed: 3.7ms preprocess, 231.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"result.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run nano model\n",
    "results_n = model_n(img1, save=True)\n",
    "result_img = results_n[0].save(filename=\"result.jpg\")\n",
    "display.Image(url=result_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cf94228-7516-4ede-a88f-910718f50a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Joseph.Lynch.CTR\\Documents\\GitHub\\Border-Bottleneck-Management\\YOLO\\..\\img\\PDN_12_02_2025.png: 384x640 1 person, 8 cars, 1 train, 1 truck, 1613.4ms\n",
      "Speed: 5.3ms preprocess, 1613.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"result.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run medium model\n",
    "results_m = model_m(img1, save=True)\n",
    "result_img = results_m[0].save(filename=\"result.jpg\")\n",
    "display.Image(url=result_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6d3d1c8-f9aa-4c77-b709-ac043f1e10f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148]],\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148]],\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148],\n",
      "        [170, 159, 148]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 63,  63,  65],\n",
      "        [ 40,  39,  42],\n",
      "        [ 49,  48,  50],\n",
      "        ...,\n",
      "        [ 63,  74,  84],\n",
      "        [ 58,  69,  79],\n",
      "        [ 66,  77,  88]],\n",
      "\n",
      "       [[ 43,  40,  43],\n",
      "        [ 46,  43,  45],\n",
      "        [ 60,  57,  59],\n",
      "        ...,\n",
      "        [ 56,  68,  78],\n",
      "        [ 55,  66,  76],\n",
      "        [ 74,  85,  95]],\n",
      "\n",
      "       [[ 51,  48,  51],\n",
      "        [ 56,  53,  55],\n",
      "        [ 72,  69,  71],\n",
      "        ...,\n",
      "        [ 55,  66,  76],\n",
      "        [ 50,  62,  72],\n",
      "        [ 81,  93, 103]]], dtype=uint8)\n",
      "orig_shape: (539, 949)\n",
      "path: 'C:\\\\Users\\\\Joseph.Lynch.CTR\\\\Documents\\\\GitHub\\\\Border-Bottleneck-Management\\\\YOLO\\\\..\\\\img\\\\PDN_12_02_2025.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict2'\n",
      "speed: {'preprocess': 5.25030000062543, 'inference': 1613.4459000004426, 'postprocess': 5.1546999984566355}\n"
     ]
    }
   ],
   "source": [
    "# results object from medium model\n",
    "print(results_m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42726571-f621-48b1-b08c-207c2435d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2., 2., 0., 7., 2., 2., 2., 2., 6., 2., 2.])\n",
      "conf: tensor([0.7958, 0.7366, 0.6368, 0.6083, 0.6072, 0.5582, 0.4918, 0.3686, 0.3286, 0.2951, 0.2753])\n",
      "data: tensor([[5.9612e+00, 3.9737e+02, 7.7846e+01, 4.4937e+02, 7.9577e-01, 2.0000e+00],\n",
      "        [5.9635e+01, 3.6703e+02, 1.1106e+02, 4.1494e+02, 7.3661e-01, 2.0000e+00],\n",
      "        [8.3995e+02, 5.1057e+02, 8.6567e+02, 5.3788e+02, 6.3682e-01, 0.0000e+00],\n",
      "        [3.8341e+02, 3.4147e+02, 4.4372e+02, 4.0184e+02, 6.0834e-01, 7.0000e+00],\n",
      "        [5.3275e+02, 2.7903e+02, 5.6775e+02, 3.1248e+02, 6.0717e-01, 2.0000e+00],\n",
      "        [0.0000e+00, 4.3898e+02, 2.6068e+01, 4.7694e+02, 5.5823e-01, 2.0000e+00],\n",
      "        [3.8312e+02, 3.4195e+02, 4.4350e+02, 4.0135e+02, 4.9180e-01, 2.0000e+00],\n",
      "        [8.7673e-02, 3.8662e+02, 3.1032e+01, 4.1626e+02, 3.6857e-01, 2.0000e+00],\n",
      "        [5.0626e+02, 1.2946e+02, 5.3029e+02, 1.6834e+02, 3.2862e-01, 6.0000e+00],\n",
      "        [4.6198e+02, 1.4194e+02, 4.7706e+02, 1.5280e+02, 2.9512e-01, 2.0000e+00],\n",
      "        [7.1829e+01, 3.3564e+02, 1.4030e+02, 3.6619e+02, 2.7528e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (539, 949)\n",
      "shape: torch.Size([11, 6])\n",
      "xywh: tensor([[ 41.9036, 423.3704,  71.8848,  51.9956],\n",
      "        [ 85.3485, 390.9836,  51.4261,  47.9094],\n",
      "        [852.8094, 524.2277,  25.7184,  27.3144],\n",
      "        [413.5651, 371.6552,  60.3113,  60.3624],\n",
      "        [550.2542, 295.7505,  34.9990,  33.4506],\n",
      "        [ 13.0342, 457.9581,  26.0684,  37.9578],\n",
      "        [413.3122, 371.6465,  60.3757,  59.4014],\n",
      "        [ 15.5600, 401.4443,  30.9447,  29.6392],\n",
      "        [518.2728, 148.8955,  24.0269,  38.8798],\n",
      "        [469.5198, 147.3693,  15.0785,  10.8577],\n",
      "        [106.0648, 350.9170,  68.4712,  30.5440]])\n",
      "xywhn: tensor([[0.0442, 0.7855, 0.0757, 0.0965],\n",
      "        [0.0899, 0.7254, 0.0542, 0.0889],\n",
      "        [0.8986, 0.9726, 0.0271, 0.0507],\n",
      "        [0.4358, 0.6895, 0.0636, 0.1120],\n",
      "        [0.5798, 0.5487, 0.0369, 0.0621],\n",
      "        [0.0137, 0.8496, 0.0275, 0.0704],\n",
      "        [0.4355, 0.6895, 0.0636, 0.1102],\n",
      "        [0.0164, 0.7448, 0.0326, 0.0550],\n",
      "        [0.5461, 0.2762, 0.0253, 0.0721],\n",
      "        [0.4948, 0.2734, 0.0159, 0.0201],\n",
      "        [0.1118, 0.6511, 0.0722, 0.0567]])\n",
      "xyxy: tensor([[5.9612e+00, 3.9737e+02, 7.7846e+01, 4.4937e+02],\n",
      "        [5.9635e+01, 3.6703e+02, 1.1106e+02, 4.1494e+02],\n",
      "        [8.3995e+02, 5.1057e+02, 8.6567e+02, 5.3788e+02],\n",
      "        [3.8341e+02, 3.4147e+02, 4.4372e+02, 4.0184e+02],\n",
      "        [5.3275e+02, 2.7903e+02, 5.6775e+02, 3.1248e+02],\n",
      "        [0.0000e+00, 4.3898e+02, 2.6068e+01, 4.7694e+02],\n",
      "        [3.8312e+02, 3.4195e+02, 4.4350e+02, 4.0135e+02],\n",
      "        [8.7673e-02, 3.8662e+02, 3.1032e+01, 4.1626e+02],\n",
      "        [5.0626e+02, 1.2946e+02, 5.3029e+02, 1.6834e+02],\n",
      "        [4.6198e+02, 1.4194e+02, 4.7706e+02, 1.5280e+02],\n",
      "        [7.1829e+01, 3.3564e+02, 1.4030e+02, 3.6619e+02]])\n",
      "xyxyn: tensor([[6.2816e-03, 7.3724e-01, 8.2030e-02, 8.3371e-01],\n",
      "        [6.2840e-02, 6.8094e-01, 1.1703e-01, 7.6983e-01],\n",
      "        [8.8509e-01, 9.4725e-01, 9.1219e-01, 9.9793e-01],\n",
      "        [4.0401e-01, 6.3353e-01, 4.6757e-01, 7.4552e-01],\n",
      "        [5.6139e-01, 5.1767e-01, 5.9827e-01, 5.7973e-01],\n",
      "        [0.0000e+00, 8.1443e-01, 2.7469e-02, 8.8486e-01],\n",
      "        [4.0371e-01, 6.3441e-01, 4.6733e-01, 7.4461e-01],\n",
      "        [9.2384e-05, 7.1730e-01, 3.2700e-02, 7.7229e-01],\n",
      "        [5.3347e-01, 2.4018e-01, 5.5878e-01, 3.1231e-01],\n",
      "        [4.8681e-01, 2.6334e-01, 5.0270e-01, 2.8348e-01],\n",
      "        [7.5689e-02, 6.2272e-01, 1.4784e-01, 6.7939e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(results_m[0].boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0a2403de-836c-494e-a784-18c2a0f0bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INteger class indices of detected objects: \n",
      "[2, 2, 0, 7, 2, 2, 2, 2, 6, 2, 2]\n",
      "Number of Objects:  11\n",
      "List of Object Labels:\n",
      "['car', 'car', 'person', 'truck', 'car', 'car', 'car', 'car', 'train', 'car', 'car']\n",
      "Confidence Levels of objects detected:\n",
      "tensor([0.7960, 0.7370, 0.6370, 0.6080, 0.6070, 0.5580, 0.4920, 0.3690, 0.3290, 0.2950, 0.2750])\n"
     ]
    }
   ],
   "source": [
    "# details of objects detected\n",
    "class_list = model_m.names   # list of potential object labels\n",
    "boxes = results_m[0].boxes   # get the bounding box info\n",
    "class_indices = boxes.cls.int().tolist()   # get the integer class of our detected objects\n",
    "print(\"INteger class indices of detected objects: \")\n",
    "print(class_indices)\n",
    "conf_list = boxes.conf\n",
    "#print(torch.round(conf_list,decimals = 3))\n",
    "\n",
    "# initialize list of object labels\n",
    "obj_labels = []\n",
    "\n",
    "# store object labels in list\n",
    "for box, class_idx in zip(boxes, class_indices):\n",
    "    class_name = class_list[class_idx]\n",
    "    #print(class_name)\n",
    "    obj_labels.append(class_name)\n",
    "    \n",
    "print(\"Number of Objects: \", len(obj_labels))\n",
    "print(\"List of Object Labels:\")\n",
    "print(obj_labels)\n",
    "print(\"Confidence Levels of objects detected:\")\n",
    "print(torch.round(conf_list,decimals = 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad0215-e04b-44de-b7bb-7ff8781d3958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
